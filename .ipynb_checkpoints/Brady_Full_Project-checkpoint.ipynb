{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "44d989e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "249067bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df=pd.read_csv(\"train.csv\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=\"Survived\"), df[\"Survived\"], test_size = 0.33)\n",
    "\n",
    "X_train[\"CabinNull?\"] = X_train.Cabin.isnull()\n",
    "X_test[\"CabinNull?\"] = X_test.Cabin.isnull()\n",
    "X_train[\"Total_Fam\"] = X_train.Parch + X_train.SibSp\n",
    "X_test[\"Total_Fam\"] = X_test.Parch + X_test.SibSp\n",
    "X_train['Age_bin'] = pd.cut(X_train['Age'], bins=[0,18,65,np.percentile(X_train.Age,100)], labels=[\"Youth\",\"Adult\", \"Elderly\"])\n",
    "X_test['Age_bin'] = pd.cut(X_test['Age'], bins=[0,18,65,np.percentile(X_test.Age,100)], labels=[\"Youth\",\"Adult\", \"Elderly\"])\n",
    "\n",
    "\n",
    "#Drop the unique columns that won't help our model. Both in the test and train datasets\n",
    "X_train.drop(columns = [\"Name\",\"Ticket\", \"PassengerId\",\"Cabin\",\"Age\"], inplace = True)\n",
    "X_test.drop(columns = [\"Name\",\"Ticket\", \"PassengerId\",\"Cabin\",\"Age\"], inplace = True)\n",
    "\n",
    "#Impute the numerical variables with mean\n",
    "X_train[\"Fare\"] = X_train[\"Fare\"].replace(np.NaN, X_train[\"Fare\"].mean())\n",
    "X_test[\"Fare\"] = X_test[\"Fare\"].replace(np.NaN, X_train[\"Fare\"].mean())\n",
    "\n",
    "#Binning - Fare\n",
    "X_train['Fare_bin'] = pd.cut(X_train['Fare'], bins=[np.percentile(X_train.Fare,0),np.percentile(X_train.Fare,25),\n",
    "                                                    np.percentile(X_train.Fare,50),\n",
    "                                                    np.percentile(X_train.Fare,75),\n",
    "                                                    np.percentile(X_train.Fare,100)], labels=[\"Lowest\",\"Low-to-Mid\", \"Mid\", \"High\"])\n",
    "X_test['Fare_bin'] = pd.cut(X_test['Fare'], bins=[np.percentile(X_train.Fare,0),np.percentile(X_train.Fare,25),\n",
    "                                                   np.percentile(X_train.Fare,50),\n",
    "                                                   np.percentile(X_train.Fare,75),\n",
    "                                                   np.percentile(X_train.Fare,100)], labels=[\"Lowest\", \"Low-to-Mid\", \"Mid\", \"High\"])\n",
    "\n",
    "\n",
    "#Change Passenger class to a string variable instead of numerical\n",
    "X_train.Pclass = X_train.Pclass.astype(str)\n",
    "X_test.Pclass = X_test.Pclass.astype(str)\n",
    "\n",
    "#Impute the Categorical variables\n",
    "#X_train.Cabin = X_train.Cabin.fillna(X_train['Cabin'].value_counts().index[0])\n",
    "#X_test.Cabin = X_train.Cabin.fillna(X_train['Cabin'].value_counts().index[0])\n",
    "\n",
    "X_train.Embarked = X_train.Embarked.fillna(X_train['Embarked'].value_counts().index[0])\n",
    "X_test.Embarked = X_test.Embarked.fillna(X_train['Embarked'].value_counts().index[0])\n",
    "\n",
    "X_train = pd.get_dummies(X_train, drop_first = True)\n",
    "X_test = pd.get_dummies(X_test, drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d6930",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "## Recursive Feature Elimination\n",
    "It works by recursively removing attributes and building a model on those attributes that remain. It uses the model accuracy to identify which attributes (and combination of attributes) contribute the most to predicting the target attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4d1c3ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True  True  True False  True  True False False  True False\n",
      " False False False]\n",
      "[3 1 1 1 1 6 1 1 5 2 1 8 4 7 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "rfe = RFECV(estimator=DecisionTreeClassifier())\n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "43f4a3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected False, Rank: 3.000\n",
      "Column: 1, Selected True, Rank: 1.000\n",
      "Column: 2, Selected True, Rank: 1.000\n",
      "Column: 3, Selected True, Rank: 1.000\n",
      "Column: 4, Selected True, Rank: 1.000\n",
      "Column: 5, Selected False, Rank: 6.000\n",
      "Column: 6, Selected True, Rank: 1.000\n",
      "Column: 7, Selected True, Rank: 1.000\n",
      "Column: 8, Selected False, Rank: 5.000\n",
      "Column: 9, Selected False, Rank: 2.000\n",
      "Column: 10, Selected True, Rank: 1.000\n",
      "Column: 11, Selected False, Rank: 8.000\n",
      "Column: 12, Selected False, Rank: 4.000\n",
      "Column: 13, Selected False, Rank: 7.000\n",
      "Column: 14, Selected False, Rank: 9.000\n"
     ]
    }
   ],
   "source": [
    "for i in range(X_train.shape[1]):\n",
    "    print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ad1d4256",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(rfe.fit_transform(X_train,y_train), columns = X_train.loc[:,list(rfe.support_)].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ae068325",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(rfe.transform(X_test), columns = X_test.loc[:,list(rfe.support_)].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "97aacd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=1)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=1)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a470d452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8203389830508474"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e539aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=1)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
